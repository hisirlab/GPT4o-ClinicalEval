import json
import time
from openai import OpenAI
import os
import base64

def encode_image(image_path):
  with open(image_path, "rb") as image_file:
    return base64.b64encode(image_file.read()).decode('utf-8')

def response_save_to_json(data, filename):
    with open(filename, 'a', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def get_response(API_Key, text_input, image_base64_url,i,temperature,image_name):
    model="gpt-4o"
    response_data={
        "ID":i+1,
        "Temperature":temperature,
        "text_input":text_input,
        "image_name":image_name,
        "Long_response":None,
        "Short_response":None,
        "Long_response_timestamp":None,
        "Long_response_time":None,
        "Long_response_Usage": {}
    }
    client=OpenAI(
        api_key=API_Key
    )
    requests = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": text_input
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_base64_url}"
                    },
                },
            ],
        }
    ]
    start_time = time.time()
    response = client.chat.completions.create(
        model=model,
        messages=requests,
        temperature=temperature
    )
    end_time=time.time()
    long_response_time = end_time - start_time
    response_data["Long_response_time"]=long_response_time
    timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(start_time))
    response_data["Long_response_timestamp"]=timestamp
    long_response = response.choices[0].message.content
    response_data["Long_response"]=long_response
    usage = response.usage
    response_data["Long_response_Usage"]={
        "prompt_tokens": usage.prompt_tokens,
        "completion_tokens": usage.completion_tokens,
        "total_tokens": usage.total_tokens
    }
    return response_data

def get_text_input(json_data):
    case_describe=json_data["case describe"]
    question=json_data["question"]
    options = []
    for opt in json_data["options"]:
        options.append(opt)
    text_input=f"Question:{case_describe}{question}\nOptions:\n"+"\n".join(options)
    option_text="\n".join(options)
    return text_input,option_text

def get_cases_input(json_file, image_folder):
    """
    Load a JSON file that contains multiple question records, match each record with its corresponding image in the
    given image folder, and convert each case into a pair of (text_input, image_base64) for model evaluation.

    The text input for each case follows the format:
        {Images}
        Question: {Question}
        Options: {Option 1}, {Option 2}, ...


    Parameters
    ----------
    json_file : str
        Path to the JSON file that stores a list of question objects.
        Each JSON object is expected to contain:
            - "image name": filename of the associated image (must exist in image_folder)
            - "question": question text
            - "options": list of options
            (and other fields used by get_text_input)

    image_folder : str
        Directory that contains all images referenced in the JSON file.
        The function will search for each image using:
            os.path.join(image_folder, image_name)


    Returns
    -------
    cases_input : list
        A list where each element is:
            [case_text_input, image_base64_url]
        - case_text_input : str
            The formatted text prompt generated by get_text_input(json_data).
        - image_base64_url : str
            Base64-encoded string of the corresponding image.

    images : list
        A list of image filenames corresponding to each case, in the same order as cases_input.
    """
    cases_input=[]
    options=[]
    images=[]
    with open(json_file, 'r', encoding='utf-8') as file:
        json_datas = json.load(file)
        for i in range(0,len(json_datas)):
            json_data=json_datas[i]
            case_text_input,option_text=get_text_input(json_data)
            image_name=json_data["image name"]
            image_path=os.path.join(image_folder,image_name)
            if not os.path.exists(image_path):
                print(image_name,"not exist")
                continue
            image_base64_url=encode_image(image_path)
            cases_input.append([case_text_input,image_base64_url])
            option=json_data["options"]
            options.append(option)
            image=json_data["image name"]
            images.append(image)
    return cases_input,images

def main():
    """
    Main pipeline for processing medical QA cases:
    - Loads JSON records and corresponding images.
    - Constructs textâ€“image input pairs.
    - Calls the GPT-4o model to generate responses.
    - Saves responseS into an output JSON file.

    Variables:
        json_file (str): Path to the input JSON file containing question records.
        image_folder (str): Directory containing case images referenced in the JSON.
        output_json (str): Path to the output file for saving model responses.
        API_Key (str): Your OpenAI API key.
        temperature (float): Decoding randomness for the model (e.g., 0.5).
        cases_input (list): List of [text_input, image_base64] pairs.
        images (list): List of image file names corresponding to each case.
    """
    json_file="JAMA_json_record.json"
    image_folder="JAMA_images"
    output_json="JAMA_output.json"
    API_Key="your api-key"
    cases_input,images=get_cases_input(json_file,image_folder)
    temperature=0.5
    for i in range(0,len(cases_input)):
        case_text_input=cases_input[i][0]
        case_image_input=cases_input[i][1]
        response_data=get_response(API_Key,case_text_input,case_image_input,i,temperature,images[i])
        response_save_to_json(response_data,output_json)
        time.sleep(3)

if __name__ == "__main__":
    main()